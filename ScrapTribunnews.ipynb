{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in c:\\users\\fz\\project clickbait\\.venv\\lib\\site-packages (2.32.3)\n",
            "Requirement already satisfied: feedparser in c:\\users\\fz\\project clickbait\\.venv\\lib\\site-packages (6.0.11)\n",
            "Requirement already satisfied: bs4 in c:\\users\\fz\\project clickbait\\.venv\\lib\\site-packages (0.0.2)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.3.0-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fz\\project clickbait\\.venv\\lib\\site-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fz\\project clickbait\\.venv\\lib\\site-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fz\\project clickbait\\.venv\\lib\\site-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fz\\project clickbait\\.venv\\lib\\site-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: sgmllib3k in c:\\users\\fz\\project clickbait\\.venv\\lib\\site-packages (from feedparser) (1.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\fz\\project clickbait\\.venv\\lib\\site-packages (from bs4) (4.13.4)\n",
            "Collecting numpy>=1.26.0 (from pandas)\n",
            "  Downloading numpy-2.3.0-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fz\\project clickbait\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\fz\\project clickbait\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\fz\\project clickbait\\.venv\\lib\\site-packages (from beautifulsoup4->bs4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\fz\\project clickbait\\.venv\\lib\\site-packages (from beautifulsoup4->bs4) (4.14.0)\n",
            "Using cached pandas-2.3.0-cp313-cp313-win_amd64.whl (11.0 MB)\n",
            "Downloading numpy-2.3.0-cp313-cp313-win_amd64.whl (12.7 MB)\n",
            "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/12.7 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.5/12.7 MB 1.5 MB/s eta 0:00:09\n",
            "   - -------------------------------------- 0.5/12.7 MB 1.5 MB/s eta 0:00:09\n",
            "   -- ------------------------------------- 0.8/12.7 MB 986.9 kB/s eta 0:00:13\n",
            "   --- ------------------------------------ 1.0/12.7 MB 1.0 MB/s eta 0:00:12\n",
            "   ---- ----------------------------------- 1.6/12.7 MB 1.3 MB/s eta 0:00:09\n",
            "   ----- ---------------------------------- 1.8/12.7 MB 1.4 MB/s eta 0:00:08\n",
            "   ----- ---------------------------------- 1.8/12.7 MB 1.4 MB/s eta 0:00:08\n",
            "   ----- ---------------------------------- 1.8/12.7 MB 1.4 MB/s eta 0:00:08\n",
            "   ----- ---------------------------------- 1.8/12.7 MB 1.4 MB/s eta 0:00:08\n",
            "   ------ --------------------------------- 2.1/12.7 MB 864.6 kB/s eta 0:00:13\n",
            "   ------ --------------------------------- 2.1/12.7 MB 864.6 kB/s eta 0:00:13\n",
            "   ------ --------------------------------- 2.1/12.7 MB 864.6 kB/s eta 0:00:13\n",
            "   ------ --------------------------------- 2.1/12.7 MB 864.6 kB/s eta 0:00:13\n",
            "   ------ --------------------------------- 2.1/12.7 MB 864.6 kB/s eta 0:00:13\n",
            "   ------ --------------------------------- 2.1/12.7 MB 864.6 kB/s eta 0:00:13\n",
            "   ------ --------------------------------- 2.1/12.7 MB 864.6 kB/s eta 0:00:13\n",
            "   ------- -------------------------------- 2.4/12.7 MB 577.2 kB/s eta 0:00:18\n",
            "   ------- -------------------------------- 2.4/12.7 MB 577.2 kB/s eta 0:00:18\n",
            "   ------- -------------------------------- 2.4/12.7 MB 577.2 kB/s eta 0:00:18\n",
            "   -------- ------------------------------- 2.6/12.7 MB 572.8 kB/s eta 0:00:18\n",
            "   -------- ------------------------------- 2.6/12.7 MB 572.8 kB/s eta 0:00:18\n",
            "   --------- ------------------------------ 2.9/12.7 MB 574.1 kB/s eta 0:00:18\n",
            "   --------- ------------------------------ 2.9/12.7 MB 574.1 kB/s eta 0:00:18\n",
            "   --------- ------------------------------ 2.9/12.7 MB 574.1 kB/s eta 0:00:18\n",
            "   --------- ------------------------------ 3.1/12.7 MB 557.2 kB/s eta 0:00:18\n",
            "   ---------- ----------------------------- 3.4/12.7 MB 571.1 kB/s eta 0:00:17\n",
            "   ---------- ----------------------------- 3.4/12.7 MB 571.1 kB/s eta 0:00:17\n",
            "   ----------- ---------------------------- 3.7/12.7 MB 572.2 kB/s eta 0:00:16\n",
            "   ----------- ---------------------------- 3.7/12.7 MB 572.2 kB/s eta 0:00:16\n",
            "   ------------ --------------------------- 3.9/12.7 MB 582.6 kB/s eta 0:00:16\n",
            "   ------------ --------------------------- 3.9/12.7 MB 582.6 kB/s eta 0:00:16\n",
            "   ------------- -------------------------- 4.2/12.7 MB 592.8 kB/s eta 0:00:15\n",
            "   -------------- ------------------------- 4.5/12.7 MB 600.6 kB/s eta 0:00:14\n",
            "   -------------- ------------------------- 4.7/12.7 MB 616.1 kB/s eta 0:00:14\n",
            "   --------------- ------------------------ 5.0/12.7 MB 632.4 kB/s eta 0:00:13\n",
            "   --------------- ------------------------ 5.0/12.7 MB 632.4 kB/s eta 0:00:13\n",
            "   ---------------- ----------------------- 5.2/12.7 MB 632.1 kB/s eta 0:00:12\n",
            "   ---------------- ----------------------- 5.2/12.7 MB 632.1 kB/s eta 0:00:12\n",
            "   ---------------- ----------------------- 5.2/12.7 MB 632.1 kB/s eta 0:00:12\n",
            "   ----------------- ---------------------- 5.5/12.7 MB 626.8 kB/s eta 0:00:12\n",
            "   ------------------ --------------------- 5.8/12.7 MB 637.9 kB/s eta 0:00:11\n",
            "   ------------------ --------------------- 6.0/12.7 MB 645.7 kB/s eta 0:00:11\n",
            "   ------------------- -------------------- 6.3/12.7 MB 661.9 kB/s eta 0:00:10\n",
            "   -------------------- ------------------- 6.6/12.7 MB 678.3 kB/s eta 0:00:10\n",
            "   --------------------- ------------------ 6.8/12.7 MB 690.3 kB/s eta 0:00:09\n",
            "   ---------------------- ----------------- 7.1/12.7 MB 703.4 kB/s eta 0:00:09\n",
            "   ----------------------- ---------------- 7.3/12.7 MB 715.4 kB/s eta 0:00:08\n",
            "   ----------------------- ---------------- 7.6/12.7 MB 723.1 kB/s eta 0:00:08\n",
            "   ------------------------ --------------- 7.9/12.7 MB 735.3 kB/s eta 0:00:07\n",
            "   ------------------------- -------------- 8.1/12.7 MB 746.9 kB/s eta 0:00:07\n",
            "   -------------------------- ------------- 8.4/12.7 MB 761.5 kB/s eta 0:00:06\n",
            "   --------------------------- ------------ 8.7/12.7 MB 764.9 kB/s eta 0:00:06\n",
            "   ---------------------------- ----------- 8.9/12.7 MB 773.7 kB/s eta 0:00:05\n",
            "   ---------------------------- ----------- 8.9/12.7 MB 773.7 kB/s eta 0:00:05\n",
            "   ---------------------------- ----------- 9.2/12.7 MB 771.1 kB/s eta 0:00:05\n",
            "   ---------------------------- ----------- 9.2/12.7 MB 771.1 kB/s eta 0:00:05\n",
            "   ----------------------------- ---------- 9.4/12.7 MB 760.1 kB/s eta 0:00:05\n",
            "   ----------------------------- ---------- 9.4/12.7 MB 760.1 kB/s eta 0:00:05\n",
            "   ------------------------------ --------- 9.7/12.7 MB 766.9 kB/s eta 0:00:04\n",
            "   ------------------------------- -------- 10.0/12.7 MB 773.9 kB/s eta 0:00:04\n",
            "   -------------------------------- ------- 10.2/12.7 MB 774.8 kB/s eta 0:00:04\n",
            "   -------------------------------- ------- 10.2/12.7 MB 774.8 kB/s eta 0:00:04\n",
            "   -------------------------------- ------- 10.5/12.7 MB 777.1 kB/s eta 0:00:03\n",
            "   -------------------------------- ------- 10.5/12.7 MB 777.1 kB/s eta 0:00:03\n",
            "   --------------------------------- ------ 10.7/12.7 MB 764.9 kB/s eta 0:00:03\n",
            "   --------------------------------- ------ 10.7/12.7 MB 764.9 kB/s eta 0:00:03\n",
            "   ---------------------------------- ----- 11.0/12.7 MB 765.8 kB/s eta 0:00:03\n",
            "   ---------------------------------- ----- 11.0/12.7 MB 765.8 kB/s eta 0:00:03\n",
            "   ----------------------------------- ---- 11.3/12.7 MB 759.2 kB/s eta 0:00:02\n",
            "   ------------------------------------- -- 11.8/12.7 MB 782.4 kB/s eta 0:00:02\n",
            "   ------------------------------------- -- 12.1/12.7 MB 791.5 kB/s eta 0:00:01\n",
            "   ---------------------------------------  12.6/12.7 MB 814.0 kB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.7/12.7 MB 816.2 kB/s eta 0:00:00\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Installing collected packages: pytz, tzdata, numpy, pandas\n",
            "\n",
            "   ---------------------------------------- 0/4 [pytz]\n",
            "   ---------------------------------------- 0/4 [pytz]\n",
            "   ---------------------------------------- 0/4 [pytz]\n",
            "   ---------------------------------------- 0/4 [pytz]\n",
            "   ---------- ----------------------------- 1/4 [tzdata]\n",
            "   ---------- ----------------------------- 1/4 [tzdata]\n",
            "   ---------- ----------------------------- 1/4 [tzdata]\n",
            "   ---------- ----------------------------- 1/4 [tzdata]\n",
            "   ---------- ----------------------------- 1/4 [tzdata]\n",
            "   ---------- ----------------------------- 1/4 [tzdata]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   -------------------- ------------------- 2/4 [numpy]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ------------------------------ --------- 3/4 [pandas]\n",
            "   ---------------------------------------- 4/4 [pandas]\n",
            "\n",
            "Successfully installed numpy-2.3.0 pandas-2.3.0 pytz-2025.2 tzdata-2025.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install requests feedparser bs4 pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tehdw_hi8-jR",
        "outputId": "46864e18-bf5f-43f4-9a64-5b858384e6f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mengambil dari: https://www.tribunnews.com/rss\n",
            "Mengambil dari: https://medan.tribunnews.com/rss\n",
            "Mengambil dari: https://jabar.tribunnews.com/rss\n",
            "Mengambil dari: https://surabaya.tribunnews.com/rss\n",
            "Mengambil dari: http://jabar.tribunnews.com/rss\n",
            "Mengambil dari: https://wartakota.tribunnews.com/rss\n",
            "Mengambil dari: https://jogja.tribunnews.com/rss\n",
            "Mengambil dari: http://jateng.tribunnews.com/rss\n",
            "Mengambil dari: http://aceh.tribunnews.com/rss\n",
            "✅ Total link yang berhasil dikumpulkan: 160\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import feedparser\n",
        "import time\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
        "    \"Referer\": \"https://www.google.com/\",\n",
        "}\n",
        "\n",
        "rss_urls = [\n",
        "    'https://www.tribunnews.com/rss',\n",
        "    'https://medan.tribunnews.com/rss',\n",
        "    'https://jabar.tribunnews.com/rss',\n",
        "    'https://surabaya.tribunnews.com/rss',\n",
        "    'http://jabar.tribunnews.com/rss',\n",
        "    'https://wartakota.tribunnews.com/rss',\n",
        "    'https://jogja.tribunnews.com/rss',\n",
        "    'http://jateng.tribunnews.com/rss',\n",
        "    'http://aceh.tribunnews.com/rss',\n",
        "]\n",
        "\n",
        "urls = set()\n",
        "for rss_url in rss_urls:\n",
        "    try:\n",
        "        print(f\"Mengambil dari: {rss_url}\")\n",
        "        resp = requests.get(rss_url, headers=headers, timeout=10)\n",
        "        feed = feedparser.parse(resp.text)\n",
        "        for entry in feed.entries:\n",
        "            urls.add(entry.link)\n",
        "        time.sleep(1)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Gagal ambil dari {rss_url}: {e}\")\n",
        "\n",
        "urls = list(urls)[:1000]\n",
        "print(f\"✅ Total link yang berhasil dikumpulkan: {len(urls)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q7GXcGyTj33O"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_berita(url):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\",\n",
        "        \"Referer\": \"https://www.google.com/\",\n",
        "        \"Accept-Language\": \"id,en-US;q=0.9,en;q=0.8\",\n",
        "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
        "    }\n",
        "    try:\n",
        "        resp = requests.get(url, headers=headers, timeout=10)\n",
        "        if resp.status_code != 200:\n",
        "            print(f\"  ⚠️ Status code: {resp.status_code}\")\n",
        "            return None\n",
        "        soup = BeautifulSoup(resp.content, \"html.parser\")\n",
        "\n",
        "        judul_tag = soup.select_one(\"h1\")\n",
        "        if not judul_tag:\n",
        "            print(\"  ⚠️ Tidak menemukan tag <h1>\")\n",
        "            return None\n",
        "\n",
        "        isi_paragraf = soup.select(\".side-article p\")\n",
        "        if not isi_paragraf:\n",
        "            print(\"  ⚠️ Tidak menemukan isi artikel\")\n",
        "            return None\n",
        "\n",
        "        judul = judul_tag.text.strip()\n",
        "        isi = \"\\n\".join([p.text.strip() for p in isi_paragraf if p.text.strip()])\n",
        "\n",
        "        tanggal_tag = soup.select_one(\"time\") or soup.select_one(\".date\")\n",
        "        tanggal = tanggal_tag.text.strip() if tanggal_tag else \"Tidak ditemukan\"\n",
        "\n",
        "        breadcrumb = soup.select(\".breadcrumb li a\")\n",
        "        kategori = breadcrumb[1].text.strip() if len(breadcrumb) > 1 else \"Tidak diketahui\"\n",
        "\n",
        "        return {\n",
        "            \"Sumber\": \"Tribunnews\",\n",
        "            \"Judul\": judul,\n",
        "            \"Isi\": isi,\n",
        "            \"Tanggal\": tanggal,\n",
        "            \"Kategori\": kategori,\n",
        "            \"Link\": url,\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Gagal scraping {url}: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Sumber': 'Tribunnews', 'Judul': 'Jutaan Jamaah Haji Tinggalkan Mina, Persiapan Tawaf Al-Wida Berjalan Lancar', 'Isi': \"TRIBUNNEWS.COM - Sebagian besar jamaah Haji telah meninggalkan Mina setelah menjalankan ritual lempar jumrah pada hari kedua Tashreeq, Minggu (8/6/2025) sore.\\nRitual ini menjadi salah satu bagian penting dari ibadah Haji.\\nDi mana jamaah melempar kerikil ke tiga pilar Jamarat yang melambangkan penolakan terhadap godaan setan, Arab News melaporkan.\\nJamaah yang meninggalkan Mina sebelum matahari terbenam hari kedua Tashreeq diperbolehkan kembali ke Makkah untuk melanjutkan rangkaian ibadah, termasuk Tawaf Al-Wida.\\nSedangkan jamaah yang belum meninggalkan Mina diwajibkan menginap satu hari lagi dan mengulangi ritual lempar jumrah pada hari ketiga Tashreeq, yaitu Senin (9/6/2025).\\nSetelah menyelesaikan ritual lempar jumrah, jamaah yang bergegas langsung menuju Masjidil Haram untuk melaksanakan Tawaf Al-Wida.\\nSebagai catatan, Tawaf Al-Wida yaitu putaran terakhir mengelilingi Ka'bah sebagai tanda perpisahan sebelum meninggalkan Tanah Suci.\\nSuasana di Masjidil Haram begitu khusyuk dan penuh semangat spiritual.\\nBanyak jamaah terlihat sangat bahagia dan penuh syukur setelah menyelesaikan salah satu perjalanan rohani terpenting dalam hidup mereka.\\nPemerintah Arab Saudi melakukan persiapan matang untuk memastikan pergerakan jamaah dari Mina ke Makkah berjalan dengan lancar dan aman.\\nJadwal keberangkatan diatur secara terperinci dalam dua hari agar tidak terjadi kepadatan di Jamarat Bridge.\\nBaca juga:  Ucap Rasa Syukur usai Tunaikan Rangkaian Ibadah Haji, Afgan: Resmi Dipanggil Pak Haji\\nHal ini juga memudahkan jamaah menuju Masjidil Haram tanpa hambatan.\\nPetugas keamanan, relawan, dan tim kesehatan dikerahkan secara maksimal untuk membantu jamaah, terutama yang sudah lanjut usia atau memiliki keterbatasan fisik.\\nMereka mendapatkan bantuan dari berbagai fasilitas seperti 400 kereta listrik dan lebih dari 10.000 kursi roda yang tersebar di area Haji.\", 'Tanggal': 'Tayang: Senin, 9 Juni 2025 14:27 WIB', 'Kategori': 'Internasional', 'Link': 'https://www.tribunnews.com/internasional/2025/06/09/jutaan-jamaah-haji-tinggalkan-mina-persiapan-tawaf-al-wida-berjalan-lancar'}\n"
          ]
        }
      ],
      "source": [
        "data = scrape_berita(urls[0])  # Ganti dengan URL yang ingin diuji\n",
        "\n",
        "# print hasil scraping\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YGVoiLwnj7Im",
        "outputId": "b3fca2e1-0e31-4e33-cad3-67106a7d0908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/160] Scraping: https://www.tribunnews.com/internasional/2025/06/09/jutaan-jamaah-haji-tinggalkan-mina-persiapan-tawaf-al-wida-berjalan-lancar\n",
            "  ↳ Data berhasil? True\n",
            "[2/160] Scraping: https://medan.tribunnews.com/2025/06/09/satlantas-polres-batubara-sosialisasikan-tertib-berlalu-lintas-di-kecamatan-sei-suka-dan-air-putih\n",
            "  ↳ Data berhasil? True\n",
            "[3/160] Scraping: https://wartakota.tribunnews.com/2025/06/09/para-rider-uji-langsung-ban-michelin-power-gp2-dan-cup2-di-sirkuit-mandalika-ini-hasilnya\n",
            "  ↳ Data berhasil? True\n",
            "[4/160] Scraping: https://jateng.tribunnews.com/2025/06/09/7-fakta-rangkuman-skandal-fajar-shabrina-indonesia-idol-dan-amanda-lucson-cinta-segitiga\n",
            "  ↳ Data berhasil? True\n",
            "[5/160] Scraping: https://aceh.tribunnews.com/2025/06/09/penyelidikan-di-kek-arun-besok-kejari-lhokseumawe-mulai-mintai-keterangan-pt-patna-pag-dan-pim\n",
            "  ↳ Data berhasil? True\n",
            "[6/160] Scraping: https://jateng.tribunnews.com/2025/06/09/kuatkan-sinergi-pelaku-wisata-dan-pemda-bupati-fahmi-road-trip-ke-beberapa-wisata-di-purbalingga\n",
            "  ↳ Data berhasil? True\n",
            "[7/160] Scraping: https://jateng.tribunnews.com/2025/06/09/26-universitas-terbaik-di-indonesia-versi-qs-world-university-ranking-2025-kampus-mana-peringkat-1\n",
            "  ↳ Data berhasil? True\n",
            "[8/160] Scraping: https://medan.tribunnews.com/2025/06/09/prediksi-skor-italia-vs-moldova-luciano-spalletti-bakal-berikan-kemenangan-di-laga-perpisahan\n",
            "  ↳ Data berhasil? True\n",
            "[9/160] Scraping: https://medan.tribunnews.com/2025/06/09/daftar-nama-48-mahasiswa-upsi-di-dalam-bus-yang-mengalami-kecelakaan-sebanyak-15-orang-tewas\n",
            "  ↳ Data berhasil? True\n",
            "[10/160] Scraping: https://jateng.tribunnews.com/2025/06/09/ashraff-abu-sekolah-swasta-gratis-langkah-nyata-cegah-putus-sekolah\n",
            "  ↳ Data berhasil? True\n",
            "[11/160] Scraping: https://surabaya.tribunnews.com/2025/06/09/idul-adha-2025-nilai-transaksi-hewan-kurban-di-kabupaten-blitar-capai-rp-992-miliar\n",
            "  ↳ Data berhasil? True\n",
            "[12/160] Scraping: https://surabaya.tribunnews.com/2025/06/09/madura-united-lepas-dua-kiper-muda-fawaid-ansory-dan-nuri-agus-ini-alasannya\n",
            "  ↳ Data berhasil? True\n",
            "[13/160] Scraping: https://wartakota.tribunnews.com/2025/06/09/kala-gubernur-dedi-mulyadi-terpesona-akan-kecantikan-gubernur-maluku-utara\n",
            "  ↳ Data berhasil? True\n",
            "[14/160] Scraping: https://jabar.tribunnews.com/2025/06/09/sosok-h-cholid-warga-bogor-meninggal-saat-sembelih-hewan-kurban-tak-pelit-bagi-ilmu-warga-berduka\n",
            "  ↳ Data berhasil? True\n",
            "[15/160] Scraping: https://surabaya.tribunnews.com/2025/06/09/kronologi-arni-terpaksa-melahirkan-di-tengah-jalan-rusak-menuju-puskesmas-ditandu-sejauh-3-km\n",
            "  ↳ Data berhasil? True\n",
            "[16/160] Scraping: https://jogja.tribunnews.com/2025/06/09/pesan-otto-hasibuan-kepada-ratusan-advokat-yang-baru-saja-dilantik\n",
            "  ↳ Data berhasil? True\n",
            "[17/160] Scraping: https://medan.tribunnews.com/2025/06/09/lirik-lagu-batak-im-sorry-ito-dipopulerkan-oleh-trio-lamtama\n",
            "  ↳ Data berhasil? True\n",
            "[18/160] Scraping: https://aceh.tribunnews.com/2025/06/09/oki-setiana-dewi-ria-ricis-belum-cerita-soal-evan-dc-music-akui-baru-tahu\n",
            "  ↳ Data berhasil? True\n",
            "[19/160] Scraping: https://surabaya.tribunnews.com/2025/06/09/dlu-kurban-72-ekor-sapi-anggota-komisi-vii-dpr-ri-beri-apresiasi\n",
            "  ↳ Data berhasil? True\n",
            "[20/160] Scraping: https://aceh.tribunnews.com/2025/06/09/video-iknr-aceh-barat-sembelih-14-hewan-kurban-untuk-ribuan-warga\n",
            "  ↳ Data berhasil? True\n",
            "[21/160] Scraping: https://jogja.tribunnews.com/2025/06/09/lirik-lagu-dan-terjemahan-not-myself-john-mayer-lyrics-suppose-i-said-i-am-on-my-best-behavior\n",
            "  ↳ Data berhasil? True\n",
            "[22/160] Scraping: https://jogja.tribunnews.com/2025/06/09/warga-sleman-tewas-kecelakaan-di-wates-tabrak-patok-pembatas-jalan\n",
            "  ↳ Data berhasil? True\n",
            "[23/160] Scraping: https://jabar.tribunnews.com/2025/06/09/cerita-violethanara-siswa-sma-2-bandung-yang-lolos-fakultas-kedokteran-unhan-ri-dengan-beasiswa\n",
            "  ↳ Data berhasil? True\n",
            "[24/160] Scraping: https://surabaya.tribunnews.com/2025/06/09/warga-dusun-bandealit-meru-betiri-jember-segera-nikmati-aliran-listrik\n",
            "  ↳ Data berhasil? True\n",
            "[25/160] Scraping: https://wartakota.tribunnews.com/2025/06/09/13-perusahaan-tambang-di-papua-dapat-hak-istimewa-dari-era-megawati-soekarnoputri\n",
            "  ↳ Data berhasil? True\n",
            "[26/160] Scraping: https://aceh.tribunnews.com/2025/06/09/aktivis-dunia-yang-diculik-israel-di-atas-kapal-madleen-menuju-gaza-terkena-zat-putih-misterius\n",
            "  ↳ Data berhasil? True\n",
            "[27/160] Scraping: https://wartakota.tribunnews.com/2025/06/09/jalan-rusak-di-ciampea-bogor-ditanami-pohon-pisang-rudy-susmanto-gercep-perbaiki\n",
            "  ↳ Data berhasil? True\n",
            "[28/160] Scraping: https://wartakota.tribunnews.com/2025/06/09/menteri-hanif-cegah-tambang-nikel-di-raja-ampat-suaka-alam-harus-dilindungi\n",
            "  ↳ Data berhasil? True\n",
            "[29/160] Scraping: https://surabaya.tribunnews.com/2025/06/09/garin-nugroho-bawa-energi-baru-dunia-film-pacitan-kompetisi-film-horor-menanti\n",
            "  ↳ Data berhasil? True\n",
            "[30/160] Scraping: https://wartakota.tribunnews.com/2025/06/09/menteri-klh-ungkap-13-perusahaan-yang-terima-hak-spesial-keruk-nikel-di-raja-ampat-papua\n",
            "  ↳ Data berhasil? True\n",
            "[31/160] Scraping: https://www.tribunnews.com/seleb/2025/06/09/10-publik-figur-yang-serukan-tagar-save-raja-ampat-ada-denny-sumargo-hingga-model-sophie-kirana\n",
            "  ↳ Data berhasil? True\n",
            "[32/160] Scraping: https://jabar.tribunnews.com/2025/06/09/gubernur-jabar-dedi-mulyadi-puji-kulit-kinclong-sherly-tjoanda-dapat-dukungan-warganet-agar-ke-kua\n",
            "  ↳ Data berhasil? True\n",
            "[33/160] Scraping: https://jogja.tribunnews.com/2025/06/09/175-jemaah-haji-asal-indonesia-wafat-di-tanah-suci-paling-banyak-karena-penyakit-jantung\n",
            "  ↳ Data berhasil? True\n",
            "[34/160] Scraping: https://jogja.tribunnews.com/2025/06/09/phri-diy-wanti-wanti-pelonggaran-rapat-di-hotel-tak-sekadar-wacana\n",
            "  ↳ Data berhasil? True\n",
            "[35/160] Scraping: https://www.tribunnews.com/regional/2025/06/09/terungkap-sehari-sebelum-meninggal-ustaz-idham-holid-sempat-ngobrol-soal-umur-beri-pesan-terakhir\n",
            "  ↳ Data berhasil? True\n",
            "[36/160] Scraping: https://jateng.tribunnews.com/2025/06/09/jalan-boulevard-kudus-rusak-lebih-dari-5-pengendara-terjatuh\n",
            "  ↳ Data berhasil? True\n",
            "[37/160] Scraping: https://jateng.tribunnews.com/2025/06/09/chord-kunci-gitar-juicy-luicy-asing-masihkah-sering-lupa-dimana-letaknya\n",
            "  ↳ Data berhasil? True\n",
            "[38/160] Scraping: https://www.tribunnews.com/seleb/2025/06/09/cuek-hadapi-nyinyiran-soal-bentuk-tubuh-jessica-mila-ingin-menyusui-anak-hingga-usia-2-tahun\n",
            "  ↳ Data berhasil? True\n",
            "[39/160] Scraping: https://jateng.tribunnews.com/2025/06/09/tak-lagi-pakai-zonasi-spmb-di-kota-pekalongan-2025-andalkan-sistem-domisili\n",
            "  ↳ Data berhasil? True\n",
            "[40/160] Scraping: https://www.tribunnews.com/bisnis/2025/06/09/bappenas-butuh-7-hingga-10-tahun-untuk-terapkan-zero-odol-secara-penuh\n",
            "  ↳ Data berhasil? True\n",
            "[41/160] Scraping: https://jabar.tribunnews.com/2025/06/09/pendidikan-berkarakter-jilid-dua-diikuti-90-orang-siswa-dari-berbagai-daerahdi-jabar-besok-dibuka\n",
            "  ↳ Data berhasil? True\n",
            "[42/160] Scraping: https://wartakota.tribunnews.com/2025/06/09/pm-mongolia-mundur-gara-gara-anak-pamer-gaya-hidup-mewah-di-medsos\n",
            "  ↳ Data berhasil? True\n",
            "[43/160] Scraping: https://jogja.tribunnews.com/2025/06/09/siapa-lawan-indonesia-di-putaran-keempat-kualifikasi-piala-dunia-2026\n",
            "  ↳ Data berhasil? True\n",
            "[44/160] Scraping: https://jogja.tribunnews.com/2025/06/09/dipinjam-warga-kendaraan-roda-tiga-milik-pemdes-ngering-klaten-tercebur-parit\n",
            "  ↳ Data berhasil? True\n",
            "[45/160] Scraping: https://jogja.tribunnews.com/2025/06/09/ac-milan-jawaban-luka-modric-saat-ditanya-soal-transfer-ke-rossoneri\n",
            "  ↳ Data berhasil? True\n",
            "[46/160] Scraping: https://surabaya.tribunnews.com/2025/06/09/profil-risto-mitrevski-bek-persebaya-surabaya-yang-tangguh-pernah-jadi-kapten-dewa-united\n",
            "  ↳ Data berhasil? True\n",
            "[47/160] Scraping: https://aceh.tribunnews.com/2025/06/09/video-amunisi-800-rudal-balistik-canggih-milik-iran-tiba-dari-tiongkok\n",
            "  ↳ Data berhasil? True\n",
            "[48/160] Scraping: https://medan.tribunnews.com/2025/06/09/lirik-lagu-karo-mulihlah-kam-bayu-dipopulerkan-oleh-kano-sembiring\n",
            "  ↳ Data berhasil? True\n",
            "[49/160] Scraping: https://medan.tribunnews.com/2025/06/09/pemko-anggarkan-pembangunan-gedung-baru-dprd-pematangsiantar-sebesar-rp-7-miliar\n",
            "  ↳ Data berhasil? True\n",
            "[50/160] Scraping: https://jateng.tribunnews.com/2025/06/09/digitalisasi-tak-menyentuh-pedagang-tua-cerita-pedagang-pakaian-di-pasar-manis-purwokerto\n",
            "  ↳ Data berhasil? True\n",
            "[51/160] Scraping: https://medan.tribunnews.com/2025/06/09/sewa-bus-usai-libur-idul-adha-48-mahasiswa-upsi-kecelakaan-bus-di-gerik-perak-15-orang-tewas\n",
            "  ↳ Data berhasil? True\n",
            "[52/160] Scraping: https://www.tribunnews.com/regional/2025/06/09/penculikan-anak-di-sukabumi-jadi-sorotan-kejahatan-pelaku-direkam-cctv-pengurus-rw-bikin-imbauan\n",
            "  ↳ Data berhasil? True\n",
            "[53/160] Scraping: https://jabar.tribunnews.com/2025/06/09/kadisdik-jabar-sebut-kondisi-sudah-darurat-minta-semua-pihak-terlibat-penerapan-jam-malam-pelajar\n",
            "  ↳ Data berhasil? True\n",
            "[54/160] Scraping: https://wartakota.tribunnews.com/2025/06/09/hut-ke-40-pt-kao-wali-kota-jakarta-timur-berharap-edukasi-kesehatan-terus-berjalan\n",
            "  ↳ Data berhasil? True\n",
            "[55/160] Scraping: https://jateng.tribunnews.com/2025/06/09/banyumas-peringkat-2-kabupaten-paling-maju-di-jawa-tengah-versi-idsd-2024-ungguli-semarang\n",
            "  ↳ Data berhasil? True\n",
            "[56/160] Scraping: https://jogja.tribunnews.com/2025/06/09/telkomsel-bagikan-660-hewan-kurban-seluruh-indonesia-sambungkan-senyuman-di-momen-iduladha-1446-h\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, url \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(urls):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(urls)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Scraping: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     data = \u001b[43mscrape_berita\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  ↳ Data berhasil?\u001b[39m\u001b[33m\"\u001b[39m , \u001b[38;5;28mbool\u001b[39m(data))\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mscrape_berita\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m      5\u001b[39m headers = {\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mUser-Agent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mReferer\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mhttps://www.google.com/\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAccept-Language\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mid,en-US;q=0.9,en;q=0.8\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAccept\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtext/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m }\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     resp = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resp.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m     14\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ⚠️ Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FZ\\Project Clickbait\\.venv\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FZ\\Project Clickbait\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FZ\\Project Clickbait\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FZ\\Project Clickbait\\.venv\\Lib\\site-packages\\requests\\sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FZ\\Project Clickbait\\.venv\\Lib\\site-packages\\requests\\models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FZ\\Project Clickbait\\.venv\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FZ\\Project Clickbait\\.venv\\Lib\\site-packages\\urllib3\\response.py:1063\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1047\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1049\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1060\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1064\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FZ\\Project Clickbait\\.venv\\Lib\\site-packages\\urllib3\\response.py:1223\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1221\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1222\u001b[39m chunk = \u001b[38;5;28mself\u001b[39m._handle_chunk(amt)\n\u001b[32m-> \u001b[39m\u001b[32m1223\u001b[39m decoded = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflush_decoder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1225\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n\u001b[32m   1227\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m decoded\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FZ\\Project Clickbait\\.venv\\Lib\\site-packages\\urllib3\\response.py:485\u001b[39m, in \u001b[36mBaseHTTPResponse._decode\u001b[39m\u001b[34m(self, data, decode_content, flush_decoder)\u001b[39m\n\u001b[32m    483\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    484\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoder:\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m         \u001b[38;5;28mself\u001b[39m._has_decoded_content = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m.DECODER_ERROR_CLASSES \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FZ\\Project Clickbait\\.venv\\Lib\\site-packages\\urllib3\\response.py:128\u001b[39m, in \u001b[36mGzipDecoder.decompress\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m         ret += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m zlib.error:\n\u001b[32m    130\u001b[39m         previous_state = \u001b[38;5;28mself\u001b[39m._state\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "berita_list = []\n",
        "for i, url in enumerate(urls):\n",
        "    print(f\"[{i+1}/{len(urls)}] Scraping: {url}\")\n",
        "    data = scrape_berita(url)\n",
        "    print(\"  ↳ Data berhasil?\" , bool(data))\n",
        "    if data:\n",
        "        berita_list.append(data)\n",
        "    time.sleep(1)\n",
        "\n",
        "df = pd.DataFrame(berita_list)\n",
        "df.to_csv(\"berita_tribunnews_lengkap.csv\", index=False)\n",
        "print(\"✅ CSV disimpan! Jumlah artikel:\", len(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "IoRISlkvkprO",
        "outputId": "a108dca7-d539-4c15-cbc5-4a84b164d17c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_32386ef8-fe69-4cd7-b0f4-4a279f4737bc\", \"berita_tribunnews_lengkap.csv\", 1)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"berita_tribunnews_lengkap.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
